mysql {
  source {
    url = "jdbc:mysql://localhost:3306/sales_data_warehouse"
    driver = "com.mysql.cj.jdbc.Driver"
    user = "root"
    password = "root"
  }
}

hive {
  warehouse = "hdfs://localhost:9000/user/hive/warehouse"
  metastore = "thrift://localhost:9083"
}

doris {
  url = "jdbc:mysql://localhost:9030"
  user = "root"
  password = "root"
  database = "sales_dw"
}

spark {
  app.name = "Sales Data ETL"
  master = "local[*]"
  executor.memory = "2g"
  executor.cores = "2"
  default.parallelism = "4"
}

etl {
  batch.size = 10000
  checkpoint.location = "/tmp/checkpoint"
  
  paths {
    base = "/data/etl"
    input = ${etl.paths.base}"/input"
    output = ${etl.paths.base}"/output"
    temp = ${etl.paths.base}"/temp"
    archive = ${etl.paths.base}"/archive"
  }
} 